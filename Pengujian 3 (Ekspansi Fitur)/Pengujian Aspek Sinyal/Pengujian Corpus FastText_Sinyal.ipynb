{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7db78a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "import sklearn\n",
    "import six\n",
    "from abc import ABCMeta\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "from scipy import sparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "import six\n",
    "import re\n",
    "import gensim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from abc import ABCMeta\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import check_X_y, check_array\n",
    "from scipy import sparse\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "from sklearn.preprocessing import normalize, binarize, LabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e372aa64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sinyal</th>\n",
       "      <th>text_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>satriafakhri_id</td>\n",
       "      <td>@yamasaiyaa untuk masalah hp lapor aja ke yg b...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['handphone', 'lapor', 'wajib', 'bantu', 'laca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Piyuuuuu21_</td>\n",
       "      <td>@bertanyarl Gatau, akhir akhir ini Telkomsel l...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>['tidak tahu', 'telkomsel', 'lambat', 'kuota',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hypersex_pr</td>\n",
       "      <td>Ada kendala kah dengan sinyal telkomsel</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>['kendala', 'sinyal', 'telkomsel']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>snwyscrtimh</td>\n",
       "      <td>@squidwardpemala @Cutimut3 @reihanahsan @sonde...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['tidak bisa', 'nomor', 'mati', 'dihidupakan',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aninadhany</td>\n",
       "      <td>@Telkomsel min, dari kmrn aplikasi my telkomse...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['admin', 'kemarin', 'aplikasi', 'punya', 'tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16986</th>\n",
       "      <td>Syaeeef</td>\n",
       "      <td>Sinyal mines, #sinyal #telkomsel #byu.id tolon...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>['sinyal', 'minus', 'tolong', 'baik', 'problem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16987</th>\n",
       "      <td>abdr40</td>\n",
       "      <td>@Telkomsel ini My Telkomsel gangguan sampe kap...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>['punya', 'telkomsel', 'ganggu', 'aduh', 'desa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16988</th>\n",
       "      <td>thepinediary</td>\n",
       "      <td>yaallah nambah2i gawean waeee esuk2 kudu neng ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['allah', 'tambah', 'kerja', 'esuk', 'neng', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16989</th>\n",
       "      <td>yudaamaraa</td>\n",
       "      <td>@Telkomsel min sinyal telkomsel di rumah saya ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>['admin', 'sinyal', 'telkomsel', 'rumah', 'dae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16990</th>\n",
       "      <td>ytojerxhi</td>\n",
       "      <td>@convomf tante nya sender pke nomor apa? kl Te...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['tante', 'kirim', 'pakai', 'nomor', 'telkomse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16991 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Username                                               Text  \\\n",
       "0      satriafakhri_id  @yamasaiyaa untuk masalah hp lapor aja ke yg b...   \n",
       "1          Piyuuuuu21_  @bertanyarl Gatau, akhir akhir ini Telkomsel l...   \n",
       "2          hypersex_pr            Ada kendala kah dengan sinyal telkomsel   \n",
       "3          snwyscrtimh  @squidwardpemala @Cutimut3 @reihanahsan @sonde...   \n",
       "4           aninadhany  @Telkomsel min, dari kmrn aplikasi my telkomse...   \n",
       "...                ...                                                ...   \n",
       "16986          Syaeeef  Sinyal mines, #sinyal #telkomsel #byu.id tolon...   \n",
       "16987           abdr40  @Telkomsel ini My Telkomsel gangguan sampe kap...   \n",
       "16988     thepinediary  yaallah nambah2i gawean waeee esuk2 kudu neng ...   \n",
       "16989       yudaamaraa  @Telkomsel min sinyal telkomsel di rumah saya ...   \n",
       "16990        ytojerxhi  @convomf tante nya sender pke nomor apa? kl Te...   \n",
       "\n",
       "       Sinyal                                        text_result  \n",
       "0         0.0  ['handphone', 'lapor', 'wajib', 'bantu', 'laca...  \n",
       "1        -1.0  ['tidak tahu', 'telkomsel', 'lambat', 'kuota',...  \n",
       "2        -1.0                 ['kendala', 'sinyal', 'telkomsel']  \n",
       "3         0.0  ['tidak bisa', 'nomor', 'mati', 'dihidupakan',...  \n",
       "4         0.0  ['admin', 'kemarin', 'aplikasi', 'punya', 'tel...  \n",
       "...       ...                                                ...  \n",
       "16986    -1.0  ['sinyal', 'minus', 'tolong', 'baik', 'problem...  \n",
       "16987    -1.0  ['punya', 'telkomsel', 'ganggu', 'aduh', 'desa...  \n",
       "16988     0.0  ['allah', 'tambah', 'kerja', 'esuk', 'neng', '...  \n",
       "16989    -1.0  ['admin', 'sinyal', 'telkomsel', 'rumah', 'dae...  \n",
       "16990     0.0  ['tante', 'kirim', 'pakai', 'nomor', 'telkomse...  \n",
       "\n",
       "[16991 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsel = pd.read_csv(r'Prepro_Sinyal.csv', usecols=['Username','Text','Sinyal','text_result'])\n",
    "tsel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53507a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsel['text_result'] = tsel['text_result'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "905d8cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sinyal</th>\n",
       "      <th>text_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>satriafakhri_id</td>\n",
       "      <td>@yamasaiyaa untuk masalah hp lapor aja ke yg b...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>handphone lapor wajib bantu lacak imei perihal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Piyuuuuu21_</td>\n",
       "      <td>@bertanyarl Gatau, akhir akhir ini Telkomsel l...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>tidak tahu telkomsel lambat kuota promo murah ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hypersex_pr</td>\n",
       "      <td>Ada kendala kah dengan sinyal telkomsel</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>kendala sinyal telkomsel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>snwyscrtimh</td>\n",
       "      <td>@squidwardpemala @Cutimut3 @reihanahsan @sonde...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tidak bisa nomor mati dihidupakan grapari nomo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aninadhany</td>\n",
       "      <td>@Telkomsel min, dari kmrn aplikasi my telkomse...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>admin kemarin aplikasi punya telkomsel ganggu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16986</th>\n",
       "      <td>Syaeeef</td>\n",
       "      <td>Sinyal mines, #sinyal #telkomsel #byu.id tolon...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>sinyal minus tolong baik problem location cama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16987</th>\n",
       "      <td>abdr40</td>\n",
       "      <td>@Telkomsel ini My Telkomsel gangguan sampe kap...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>punya telkomsel ganggu aduh desak pakai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16988</th>\n",
       "      <td>thepinediary</td>\n",
       "      <td>yaallah nambah2i gawean waeee esuk2 kudu neng ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>allah tambah kerja esuk neng grapari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16989</th>\n",
       "      <td>yudaamaraa</td>\n",
       "      <td>@Telkomsel min sinyal telkomsel di rumah saya ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>admin sinyal telkomsel rumah daerah rawabunga ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16990</th>\n",
       "      <td>ytojerxhi</td>\n",
       "      <td>@convomf tante nya sender pke nomor apa? kl Te...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tante kirim pakai nomor telkomsel langsung gra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16991 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Username                                               Text  \\\n",
       "0      satriafakhri_id  @yamasaiyaa untuk masalah hp lapor aja ke yg b...   \n",
       "1          Piyuuuuu21_  @bertanyarl Gatau, akhir akhir ini Telkomsel l...   \n",
       "2          hypersex_pr            Ada kendala kah dengan sinyal telkomsel   \n",
       "3          snwyscrtimh  @squidwardpemala @Cutimut3 @reihanahsan @sonde...   \n",
       "4           aninadhany  @Telkomsel min, dari kmrn aplikasi my telkomse...   \n",
       "...                ...                                                ...   \n",
       "16986          Syaeeef  Sinyal mines, #sinyal #telkomsel #byu.id tolon...   \n",
       "16987           abdr40  @Telkomsel ini My Telkomsel gangguan sampe kap...   \n",
       "16988     thepinediary  yaallah nambah2i gawean waeee esuk2 kudu neng ...   \n",
       "16989       yudaamaraa  @Telkomsel min sinyal telkomsel di rumah saya ...   \n",
       "16990        ytojerxhi  @convomf tante nya sender pke nomor apa? kl Te...   \n",
       "\n",
       "       Sinyal                                        text_result  \n",
       "0         0.0  handphone lapor wajib bantu lacak imei perihal...  \n",
       "1        -1.0  tidak tahu telkomsel lambat kuota promo murah ...  \n",
       "2        -1.0                           kendala sinyal telkomsel  \n",
       "3         0.0  tidak bisa nomor mati dihidupakan grapari nomo...  \n",
       "4         0.0  admin kemarin aplikasi punya telkomsel ganggu ...  \n",
       "...       ...                                                ...  \n",
       "16986    -1.0  sinyal minus tolong baik problem location cama...  \n",
       "16987    -1.0            punya telkomsel ganggu aduh desak pakai  \n",
       "16988     0.0               allah tambah kerja esuk neng grapari  \n",
       "16989    -1.0  admin sinyal telkomsel rumah daerah rawabunga ...  \n",
       "16990     0.0  tante kirim pakai nomor telkomsel langsung gra...  \n",
       "\n",
       "[16991 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def join_text_list(text):\n",
    "    texts = ast.literal_eval(text)\n",
    "    return ' '.join([text for text in texts])\n",
    "\n",
    "tsel['text_result'] = tsel['text_result'].apply(join_text_list)\n",
    "tsel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484c84e4",
   "metadata": {},
   "source": [
    "## Ektraksi Fitur TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a85047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(tsel['text_result'], tsel['Sinyal'], test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5764870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=1000, ngram_range=(1, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1000, ngram_range=(1, 2))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=1000, ngram_range=(1, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors= TfidfVectorizer(ngram_range=(1,2), max_features = 1000)\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca115446",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfx_train = vectors.fit_transform(x_train.astype(str))\n",
    "tfidfx_test = vectors.transform(x_test.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "324e2420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0    9643\n",
       " 0.0    6877\n",
       " 1.0     471\n",
       "Name: Sinyal, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsel['Sinyal'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d11cf0d",
   "metadata": {},
   "source": [
    "## Ekspansi Fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58f6009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model trained\n",
    "model_exp = FastText.load('model_ntwt/fasttext/Twitter_Berita.fasttext').wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cba7e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_expansion(df,feature):\n",
    "    for col in tqdm(df.columns): #loop per kolom\n",
    "        try: \n",
    "            sim_word = model_exp.similar_by_word(col, topn = 20) #Mencari similarity berdasarkan nilai n\n",
    "        except:\n",
    "            sim_word = []\n",
    "        if sim_word != []: #jika similarity tidak kosong\n",
    "            for term in [sim_word[i][0] for i in range(len(sim_word))]: #loop per-word yang ada di Similarity\n",
    "                if term in feature:\n",
    "                    #untuk semua kolom yang mempunyai nilai 0 di kolom, tetapi mempunyai nilai yang bukan 0 pada kolom term\n",
    "                    #nilainya diganti dengan nilai kolom term yang mempunyai nilai bukan 0\n",
    "                    df[col][(df[col]==0) & (df[term]!=0)] = df[term][(df[col]==0) & (df[term]!=0)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d9bd824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ef = vectors.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5cb2eeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat dataframe data test & train\n",
    "tsel_x_train = pd.DataFrame(tfidfx_train.todense(), columns = feature_ef)\n",
    "tsel_x_test = pd.DataFrame(tfidfx_test.todense(), columns = feature_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "03528360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:10<00:00, 98.18it/s]\n"
     ]
    }
   ],
   "source": [
    "dfexp_x_train= feature_expansion(tsel_x_train, feature_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fa549575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:08<00:00, 112.24it/s]\n"
     ]
    }
   ],
   "source": [
    "dfexp_x_test = feature_expansion(tsel_x_test, feature_ef)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6173d7ae",
   "metadata": {},
   "source": [
    "## Klasifikasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4db3a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBSVM(six.with_metaclass(ABCMeta, BaseEstimator, ClassifierMixin)):\n",
    "    def __init__(self, alpha=1.0, C=1.0, max_iter=10000):\n",
    "        self.alpha = alpha\n",
    "        self.max_iter = max_iter\n",
    "        self.C = C\n",
    "        self.svm_ = [] # fuggly\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y, 'csr')\n",
    "        _, n_features = X.shape\n",
    "\n",
    "        labelbin = LabelBinarizer()\n",
    "        Y = labelbin.fit_transform(y)\n",
    "        self.classes_ = labelbin.classes_\n",
    "        if Y.shape[1] == 1:\n",
    "            Y = np.concatenate((1 - Y, Y), axis=1)\n",
    "\n",
    "        # LabelBinarizer().fit_transform() returns arrays with dtype=np.int64.\n",
    "        # so we don't have to cast X to floating point\n",
    "        Y = Y.astype(np.float64)\n",
    "\n",
    "        # Count raw events from data\n",
    "        n_effective_classes = Y.shape[1]\n",
    "        self.class_count_ = np.zeros(n_effective_classes, dtype=np.float64)\n",
    "        self.ratios_ = np.full((n_effective_classes, n_features), self.alpha,\n",
    "                                 dtype=np.float64)\n",
    "        self._compute_ratios(X, Y)\n",
    "\n",
    "        # flugglyness\n",
    "        for i in range(n_effective_classes):\n",
    "            X_i = X.multiply(self.ratios_[i])\n",
    "            svm = LinearSVC(C=self.C, max_iter=self.max_iter)\n",
    "            Y_i = Y[:,i]\n",
    "            svm.fit(X_i, Y_i)\n",
    "            self.svm_.append(svm) \n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_effective_classes = self.class_count_.shape[0]\n",
    "        n_examples = X.shape[0]\n",
    "\n",
    "        D = np.zeros((n_effective_classes, n_examples))\n",
    "\n",
    "        for i in range(n_effective_classes):\n",
    "            X_i = X.multiply(self.ratios_[i])\n",
    "            D[i] = self.svm_[i].decision_function(X_i)\n",
    "        \n",
    "        return self.classes_[np.argmax(D, axis=0)]\n",
    "        \n",
    "    def _compute_ratios(self, X, Y):\n",
    "        \"\"\"Count feature occurrences and compute ratios.\"\"\"\n",
    "        if np.any((X.data if issparse(X) else X) < 0):\n",
    "            raise ValueError(\"Input X must be non-negative\")\n",
    "\n",
    "        self.ratios_ += safe_sparse_dot(Y.T, X)  # ratio + feature_occurrance_c\n",
    "        normalize(self.ratios_, norm='l1', axis=1, copy=False)\n",
    "        row_calc = lambda r: np.log(np.divide(r, (1 - r)))\n",
    "        self.ratios_ = np.apply_along_axis(row_calc, axis=1, arr=self.ratios_)\n",
    "        check_array(self.ratios_)\n",
    "        self.ratios_ = sparse.csr_matrix(self.ratios_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "10b15bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_csr = sparse.csr_matrix(dfexp_x_train)\n",
    "x_test_csr = sparse.csr_matrix(dfexp_x_test)\n",
    "model = NBSVM()\n",
    "\n",
    "model.fit(x_train_csr,y_train)\n",
    "y_pred_exp = model.predict(x_test_csr)\n",
    "y_true = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571d3e9b",
   "metadata": {},
   "source": [
    "### Top 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6be19ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1844   64   21]\n",
      " [  94 1272    9]\n",
      " [  62    9   24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.92      0.96      0.94      1929\n",
      "         0.0       0.95      0.93      0.94      1375\n",
      "         1.0       0.44      0.25      0.32        95\n",
      "\n",
      "    accuracy                           0.92      3399\n",
      "   macro avg       0.77      0.71      0.73      3399\n",
      "weighted avg       0.92      0.92      0.92      3399\n",
      "\n",
      "Precision:  0.7707231171692138\n",
      "Recall:  0.7112194020089575\n",
      "F1:  0.7320343352032462\n",
      "Accuracy:  0.9238011179758753\n"
     ]
    }
   ],
   "source": [
    "#example training\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "#[None, 'micro', 'macro', 'weighted'].\n",
    "print(confusion_matrix(y_true,y_pred_exp))\n",
    "print(classification_report(y_true,y_pred_exp))\n",
    "print(\"Precision: \",precision_score(y_true, y_pred_exp, average=\"macro\"))\n",
    "print(\"Recall: \",recall_score(y_true, y_pred_exp, average=\"macro\"))\n",
    "print(\"F1: \",f1_score(y_true, y_pred_exp,  average=\"macro\"))\n",
    "print(\"Accuracy: \",accuracy_score(y_true, y_pred_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "88d69bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.830398110037282"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### ROC-AUC\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "y_pred_roc = enc.fit_transform(np.array(y_pred_exp).reshape(-1,1))\n",
    "Y_pred = y_pred_roc.toarray()\n",
    "\n",
    "y_true_r = enc.fit_transform(np.array(y_true).reshape(-1,1))\n",
    "y_true_roc = y_true_r.toarray()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_true_roc,Y_pred, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064529d5",
   "metadata": {},
   "source": [
    "### Top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "30092db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1836   67   26]\n",
      " [  93 1273    9]\n",
      " [  61    9   25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.92      0.95      0.94      1929\n",
      "         0.0       0.94      0.93      0.93      1375\n",
      "         1.0       0.42      0.26      0.32        95\n",
      "\n",
      "    accuracy                           0.92      3399\n",
      "   macro avg       0.76      0.71      0.73      3399\n",
      "weighted avg       0.92      0.92      0.92      3399\n",
      "\n",
      "Precision:  0.7609805679414285\n",
      "Recall:  0.7135881893337898\n",
      "F1:  0.7314030940609522\n",
      "Accuracy:  0.9220358929096794\n"
     ]
    }
   ],
   "source": [
    "#example training\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "#[None, 'micro', 'macro', 'weighted'].\n",
    "print(confusion_matrix(y_true,y_pred_exp))\n",
    "print(classification_report(y_true,y_pred_exp))\n",
    "print(\"Precision: \",precision_score(y_true, y_pred_exp, average=\"macro\"))\n",
    "print(\"Recall: \",recall_score(y_true, y_pred_exp, average=\"macro\"))\n",
    "print(\"F1: \",f1_score(y_true, y_pred_exp,  average=\"macro\"))\n",
    "print(\"Accuracy: \",accuracy_score(y_true, y_pred_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c1f6384d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8313100059643096"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### ROC-AUC\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "y_pred_roc = enc.fit_transform(np.array(y_pred_exp).reshape(-1,1))\n",
    "Y_pred = y_pred_roc.toarray()\n",
    "\n",
    "y_true_r = enc.fit_transform(np.array(y_true).reshape(-1,1))\n",
    "y_true_roc = y_true_r.toarray()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_true_roc,Y_pred, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8007089",
   "metadata": {},
   "source": [
    "### Top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "143e6c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1835   66   28]\n",
      " [ 103 1261   11]\n",
      " [  62    9   24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.92      0.95      0.93      1929\n",
      "         0.0       0.94      0.92      0.93      1375\n",
      "         1.0       0.38      0.25      0.30        95\n",
      "\n",
      "    accuracy                           0.92      3399\n",
      "   macro avg       0.75      0.71      0.72      3399\n",
      "weighted avg       0.91      0.92      0.91      3399\n",
      "\n",
      "Precision:  0.7474382188004943\n",
      "Recall:  0.7069975253889472\n",
      "F1:  0.7227204716475685\n",
      "Accuracy:  0.9179170344218888\n"
     ]
    }
   ],
   "source": [
    "#example training\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "#[None, 'micro', 'macro', 'weighted'].\n",
    "print(confusion_matrix(y_true,y_pred_exp))\n",
    "print(classification_report(y_true,y_pred_exp))\n",
    "print(\"Precision: \",precision_score(y_true, y_pred_exp, average=\"macro\"))\n",
    "print(\"Recall: \",recall_score(y_true, y_pred_exp, average=\"macro\"))\n",
    "print(\"F1: \",f1_score(y_true, y_pred_exp,  average=\"macro\"))\n",
    "print(\"Accuracy: \",accuracy_score(y_true, y_pred_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7ff7602f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8266480780245448"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### ROC-AUC\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "y_pred_roc = enc.fit_transform(np.array(y_pred_exp).reshape(-1,1))\n",
    "Y_pred = y_pred_roc.toarray()\n",
    "\n",
    "y_true_r = enc.fit_transform(np.array(y_true).reshape(-1,1))\n",
    "y_true_roc = y_true_r.toarray()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_true_roc,Y_pred, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a676eb3e",
   "metadata": {},
   "source": [
    "### Top 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fed98ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1827   72   30]\n",
      " [  89 1271   15]\n",
      " [  61   10   24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.92      0.95      0.94      1929\n",
      "         0.0       0.94      0.92      0.93      1375\n",
      "         1.0       0.35      0.25      0.29        95\n",
      "\n",
      "    accuracy                           0.92      3399\n",
      "   macro avg       0.74      0.71      0.72      3399\n",
      "weighted avg       0.91      0.92      0.92      3399\n",
      "\n",
      "Precision:  0.7371158307359403\n",
      "Recall:  0.708039358965773\n",
      "F1:  0.7199949932050639\n",
      "Accuracy:  0.9185054427772874\n"
     ]
    }
   ],
   "source": [
    "#example training\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "#[None, 'micro', 'macro', 'weighted'].\n",
    "print(confusion_matrix(y_true,y_pred_exp))\n",
    "print(classification_report(y_true,y_pred_exp))\n",
    "print(\"Precision: \",precision_score(y_true, y_pred_exp, average=\"macro\"))\n",
    "print(\"Recall: \",recall_score(y_true, y_pred_exp, average=\"macro\"))\n",
    "print(\"F1: \",f1_score(y_true, y_pred_exp,  average=\"macro\"))\n",
    "print(\"Accuracy: \",accuracy_score(y_true, y_pred_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5caa373a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.827990595309524"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### ROC-AUC\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "y_pred_roc = enc.fit_transform(np.array(y_pred_exp).reshape(-1,1))\n",
    "Y_pred = y_pred_roc.toarray()\n",
    "\n",
    "y_true_r = enc.fit_transform(np.array(y_true).reshape(-1,1))\n",
    "y_true_roc = y_true_r.toarray()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_true_roc,Y_pred, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23368542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
